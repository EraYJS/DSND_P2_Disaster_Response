# Disaster Response
> a project from  [Data Scientist NanoDegree programme by Udacity](https://www.udacity.com/course/data-scientist-nanodegree--nd025)

This project aims to extract useful information about natual disasters from
messages on social networks.

The project consists of the following three parts:



<a name="ETL Pipeline"></a>
## ETL Pipeline

ETL is the abbreviation for Extract-Transform-Load. The pipeline extract data
from files (can also support databases and web apis), and then performs basic
transformation and cleaning on the data before loading the data to a database
structure.

<a name="ML Pipeline"></a>
## ML Pipeline

The ML pipeline takes the text data from the database generated by the ETL
pipeline, extract TD-IDF and other features, and fit a multi-output model
to classify if the message is disaster related and in what way.

 <a name="Web Application"></a>
## Web Application

Web application constitute a web page containing model performance statistics
on given data, and also provide real time prediction service.

<a name="Run"></a>
## Run the code

<a name="Dependencies"></a>
### Dependencies

Running this project reqires the following packages.
- flask==1.1.1
- nltk==3.4.5
- numpy==1.18.1
- pandas==1.0.0
- plotly==4.5.0
- python==3.7.6
- re2==2019.08.01
- requests==2.22.0
- scikit-learn==0.22.1
- scipy==1.4.1
- sqlalchemy==1.3.15
- sqlite=3.31.1
- xgboost==1.0.2
- yaml==0.1.7

### How to run

1. To run the whole project

```shell script

```

2. To run just the ETL pipeline

```shell script
python etl_ppl.py -m data/messages.csv -c data/categories.csv -d data/disaster_sn_msg.db
```

3. To run just the ML pipeline

```shell script

```
